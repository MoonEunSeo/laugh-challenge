# AI_pipeline/core/ai_module.py

import os
import time
import json
from google import genai
from dotenv import load_dotenv
from google.genai import types

# .env ë¡œë“œ
load_dotenv("/workspace/AI_emotion_browser/AI_pipeline/.env")

API_KEY = os.getenv("GOOGLE_API_KEY")

if not API_KEY:
    raise RuntimeError("âŒ GOOGLE_API_KEY is missing!")

client = genai.Client(api_key=API_KEY)


# ------------------------------------------------------------
# 1) Gemini Files Upload
# ------------------------------------------------------------
def upload_frames_to_gemini(frame_paths):
    uploaded_ids = []

    for path in frame_paths:
        uploaded = client.files.upload(
            file=path,
            #mime_type="image/jpeg"
        )
        uploaded_ids.append(uploaded.name)
        print("ğŸ“¤ ì—…ë¡œë“œë¨:", uploaded.name)

    return uploaded_ids


# ------------------------------------------------------------
# 2) Files ACTIVE ëŒ€ê¸°
# ------------------------------------------------------------
def wait_until_active(file_ids):
    print("â³ File ìƒíƒœ í™•ì¸ ì¤‘â€¦")

    for fid in file_ids:
        while True:
            f = client.files.get(name=fid)
            print(f" â¤ {fid} ìƒíƒœ: {f.state}")

            if f.state == "ACTIVE":
                break
            elif f.state == "FAILED":
                raise RuntimeError(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {fid}")

            time.sleep(0.3)

    print("ğŸ‰ ëª¨ë“  íŒŒì¼ ACTIVE!")


# ------------------------------------------------------------
# 3) LLM ë¶„ì„
# ------------------------------------------------------------
PROMPT = """
ë‹¤ìŒ ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ë¥¼ ë¶„ì„í•´ì„œ ì‚¬ìš©ìê°€ ì–´ë–¤ ì¥ë©´ì—ì„œ ì›ƒì—ˆëŠ”ì§€ JSON í˜•íƒœë¡œ ì •í™•íˆ ì¶œë ¥í•´ì¤˜.

1) youtube ê²€ìƒ‰ì„ ìœ„í•œ íƒœê·¸ 3ê°œ  
â†’ ë°˜ë“œì‹œ 'ëª…ì‚¬' í˜•íƒœë¡œ ì¶œë ¥  
â†’ ì˜ìƒ ë§¥ë½/ìƒí™©/ìºë¦­í„°ë¥¼ í‘œí˜„í•˜ëŠ” ë‹¨ì–´ ìœ„ì£¼  
â†’ ì˜ˆ: ['í¬ì¥ë§ˆì°¨', 'ì»¤í”Œ', 'ë³‘ë§›']

2) ì‚¬ìš©ìì˜ ì›ƒìŒì„ ìœ ë°œí•œ ê°ì„± ë¼ë²¨ 1ê°œ  
â†’ ì•„ë˜ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ì„ íƒ:
   ['ë³‘ë§›', 'í’ì', 'ë°˜ì „', 'ê·€ì—¬ì›€', 'ê°ë™', 'ê³µê°', 'ì¼ìƒìœ ë¨¸', 'ìŠ¬ë©ìŠ¤í‹±', 'ì˜ˆì¸¡ë¶ˆê°€ëŠ¥', 'ë‹¹í™©', 'ì¦‰í¥', 'ì „ì—¼ì„±', 'ìƒí™©ê°œê·¸', 'íŒ©íŠ¸í­ê²©']

3) ê°„ë‹¨í•œ ìš”ì•½ ë¬¸ì¥ 1ê°œ

í˜•ì‹ ì˜ˆì‹œëŠ” ì•„ë˜ì™€ ë™ì¼í•˜ê²Œ ìœ ì§€:

{
  "tags": ["ìƒí™©", "ìºë¦­í„°", "ê°ì •"],
  "label": "ê°ì •ìš”ì•½",
  "summary": "ì§§ì€ ì„¤ëª…"
}

ì„¤ëª… ì—†ì´ JSONë§Œ ì¶œë ¥í•´.
"""


def analyze_frames_with_llm(file_ids):
    contents = [client.files.get(name=fid) for fid in file_ids]

    schema = types.Schema(
        type=types.Type.OBJECT,
        properties={
            "tags": types.Schema(type=types.Type.ARRAY, items=types.Schema(type=types.Type.STRING)),
            "label": types.Schema(type=types.Type.STRING),
            "summary": types.Schema(type=types.Type.STRING)
        },
        required=["tags", "label", "summary"]
    )

    response = client.models.generate_content(
        model="models/gemini-2.5-pro",
        contents=contents + [PROMPT],
        config=types.GenerateContentConfig(
            response_mime_type="application/json",
            response_schema=schema
        ),
    )

    print("ğŸ¯ LLM Structured Output:", response)

    # âš ï¸ ì‹¤ì œ JSON string ì¶”ì¶œ
    json_text = response.candidates[0].content.parts[0].text

    # dictë¡œ íŒŒì‹±
    data = json.loads(json_text)

    return {
        "tags": data.get("tags", []),
        "label": data.get("label", ""),
        "summary": data.get("summary", ""),
    }
# ------------------------------------------------------------
# 4) Files ì‚­ì œ
# ------------------------------------------------------------
def cleanup_gemini_files(file_ids):
    for fid in file_ids:
        client.files.delete(name=fid)
        print("ğŸ—‘ï¸ ì‚­ì œë¨:", fid)
